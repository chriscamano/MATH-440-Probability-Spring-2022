\documentclass[12pt]{article}
\usepackage[pdftex]{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\pagestyle{empty}
\author{Chris Camano: ccamano@sfsu.edu}
\title{MATH 440  Homework 7 }
\date{3/25/2022}

\topmargin -0.6in
\headsep 0.40in
\oddsidemargin 0.0in
\textheight 9.0in
\textwidth 6.5in

\newcommand{\econst}{\mathrm{e}}
\newcommand{\diff}{\mathrm{d}}
\newcommand{\dwrt}[1]{\frac{\diff}{\diff #1}}
%%%%%%Macros for 425%%%%%%%%%%%%%%%%%%%
\newcommand{\q}{\quad}
\newcommand{\tab}{\\\\}
\renewcommand{\labelenumi}{\alph{enumi})}
\newcommand{\sect}[1]{\section*{#1}}

%%%%%%Vector Spaces%%%%%%%%%%%%%%%%%%%
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\rtwo}{\mathbb{R}^2}
\newcommand{\mxn}{{mxn}}

%%%%%%Sets and common phrases%%%%%%%%%
\newcommand{\Axb}{\textbf{Ax=b} }
\newcommand{\Axz}{\textbf{Ax=0} }
\newcommand{\dim}{\text{dim}}
\newcommand{\lc}{linear combination }
\newcommand{\let}{\text{Let }}
\newcommand{\tf}{\therefore}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\everymath={\displaystyle}


\begin{document}
\maketitle
\begin{center}
  \textbf{3.5) 6,14,20,32}\\
  \textbf{3.6) 8,12,18,20}\\
\end{center}


\sect{3.5.6}
\begin{proof}
  given a sample size \textbf{n=20} and a proability of defect \textbf{p=.04} the distibution of x can be modeled by a binomial distribution. Therefore
  \[
    E(X)=np=20(.04)=.8
  \]
\end{proof}\\
\sect{3.5.14}
\begin{proof}
   Given a sample size of \textbf{n=15} observations we require a measurement of proability to discern the expected value within the given interval. the probability the continuous random variable x lies within the given interval can be found by integrating over the probability density function within the given bounds:
   \[
        \int_{\frac{1}{2}}^13y^2dy=3\int_{\frac{1}{2}}^1y^2dy=3(\frac{7}{24})=\frac{7}{8}
    \]
    \[
      E(X)=np=15(\frac{7}{8})=13.125
    \]

\end{proof}\\
\sect{3.5.20}
\begin{proof}
   Given:
   \[
    E(X)=\sum_{\forall k }2^kp_X(2^k)
   \]
   We can substitute the value for X represented as $2^k$ in the original example to yeild.
   \[
       E(X)=\sum_{\forall k }c^kp_X(2^k)
   \]
   as in this new problem the amount won each time can vary between 0 and 2 dollars raised to some power k. \\
   Adjusting bounds yeilds:
   \[
      E(X)=\sum_{k=1}^\infty c^kp_X(2^k)=\sum_{k=1}^\infty c^k\frac{1}{2^k}=\sum_{k=1}^\infty \Big(\frac{c}{2}\Big)^k
   \]
   To use the sum of a geometric series rule we must start at k =0 therefore we will adjust the bounds of the sum.
   \[
    \sum_{k=1}^\infty \Big(\frac{c}{2}\Big)^k=\Big(\sum_{k=0}^\infty \Big(\frac{c}{2}\Big)^k\Big)-1
   \]
   as the difference between the sum from 0 and 1 is only 1..
   Applying the geometric rule for convergent series:
   \[
     \frac{1}{1-\frac{c}{2}}-1=\frac{c}{2-c}
   \]
   \textbf{b)}\\
   Letting the corresponding value of x correlate with a logarithm yeilds:
   \[
        E(X)=\sum_{\forall k }log2^kp_X(2^k)
   \]
   Adjusting bounds again:
   \[
        E(X)=\sum_{k=1 }^\infty log2^kp_X(2^k)
   \]
   Substituting probability:
   \[
     E(X)=\sum_{k=1 }^\infty log2^k\Big(\frac{1}{2}\Big)^k=\sum_{k=1 }^\infty \frac{log2^k}{2^k}=\sum_{k=1 }^\infty k\frac{log2}{2^k}=log2\sum_{k=1 }^\infty \frac{k}{2^k}
   \]
   \begin{align*}
     &log2\sum_{k=1 }^\infty \frac{k}{2^k}=\\
     &log2\sum_{k=1 }^\inf ty k(\frac{1}{2})^k=\\
     &log2\frac{.5}{(1-.5)^2}=2log2=.6021
   \end{align*}
   For more information regarding why the infinite sum of k over $2^k$ follows the convention of $\frac{x}{(1-x)^2}$ see
  https://math.stackexchange.com/questions/1072038/infinite-series-sum-k-1-infty-frack2k-and-sum-k-1-infty-frack
\end{proof}\\
\sect{3.5.32}
\begin{proof}
  \[
    f_Y(y)=6y(1-y)
  \]
  \begin{align*}
    &E(5Y^2)=5\int_0^1y^26y(1-y)dy=\\
    &E(5Y^2)=5\int_0^1 6y^3-6y^4dy=\\
    &E(5Y^2)=5[\frac{6y^4}{4}-\frac{6y^5}{5}\Big|_0^1]=1.5
  \end{align*}
  For these dimensions the expected value should be 1.5. Since this a problem of volume I suppose it should be 1.5 inches cubed.
\end{proof}\\
\sect{3.6.8}
\begin{proof}
  \textbf{a)}\\
  \[
    \int_1^\infty \frac{2}{y^3}=1
  \]
  \begin{align*}
    &\int_1^\infty \frac{2}{y^3}dy=1\\
    &2\lim_{b\rightarrow \infty}\int_1^b \frac{1}{y^3}dy=1\\
    &2\lim_{b\rightarrow \infty} \frac{-1}{2y^2}\Big|_1^b=1\\
    &-\lim_{b\rightarrow \infty} \frac{1}{y^2}\Big|_1^b=1\\
    &-\lim_{b\rightarrow \infty}\Big(\frac{1}{b^2}-1)=1\\
    &-\lim_{b\rightarrow \infty}\frac{1}{b^2}+\lim_{b\rightarrow \infty}1=1\\
    &1=1
  \end{align*}
  \textbf{b)}\\
  \[
    E(X)=\int_1^\infty y(\frac{2}{y^3})dy=\int_1^\infty \frac{2}{y^2}dy=\lim_{b\rightarrow \infty}\int_1^b2y^{-2}dy=\lim_{b\rightarrow \infty}\frac{-2}{y}\Big|_1^b=2
  \]
  \textbf{c)}\\
  To calculate variance we must fisrst calculate the expected value for the random variable squared.
  \[
    E(Y^2)=\int_1^by^2(\frac{2}{y^3}dy)=\lim_{b\rightarrow \infty}2ln(y)\Big|_1^b=\infty
  \]
  since part of the required computation for the varianve is infinite the variance cannot be measured in a finite manner.
\end{proof}\\
\sect{3.6.12}
\begin{proof}
  for an exponential distribution:
  \[
    E(x)=\frac{1}{\lambda} \quad V(x)=\frac{1}{\lambda^2}
  \]
  therefore:
  \[
    P[Y>E(Y)+2\sqrt{V(Y)}]=P[Y>\frac{1}{\lambda}+2\sqrt{\frac{1}{\lambda^2}}]
  \]
  \[
  P[Y>\frac{1}{\lambda}+2\sqrt{\frac{1}{\lambda^2}}]=P[Y>\frac{1}{2}+2\sqrt{\frac{1}{4}}]=P[Y>1]=1-P[y\leq 1]=1-2\int_0^1e^{-2y}dy=.135335
  \]
\end{proof}\\
\sect{3.6.18}
\begin{proof}
  For a uniform dist. $f_Y(y)=\frac{1}{b-a}$ or in this case  $f_Y(y)=\frac{1}{3}$. To compute the expected value and variance of this function we will use the short cut results acquired through integration :
  \[
    E(X)=\frac{a+b}{2}\quad V(X)=\frac{(a-b)^2}{12}
  \]
  in this case:
  \[
    E(X)=\frac{11}{2}\quad V(X)=\frac{3}{4}
  \]
  By linearity:
  \begin{align*}
    &E(W_1)=.2281+.9948E(Y)\\
    &E(W_1)=.2281+5.4714=\\
    &E(W_1)=5.6995
  \end{align*}
  \begin{align*}
    &V(W_1)=.9948^2V(Y)+V(E_1)\\
    &V(W_1)=.74222+.0427=\\
    &V(W_1)=.78492
  \end{align*}
  \begin{align*}
    &E(W_2)=-.0748+1.0024E(Y)\\
    &E(W_2)=-.0748+5.5132=\\
    &E(W_2)=5.4384
  \end{align*}
  \begin{align*}
    &V(W_2)=1.0024^2V(Y)+V(E_2)\\
    &V(W_2)=.753604+.0159=\\
    &V(W_2)=.769504
  \end{align*}

  It is clear that for the second procedure the expected value is close to the desired mean as the difference from the mean is less for procedure two compared to procedure 1. It can also be seen that procedure 2 yields a lower overall variance.
\end{proof}\\
\sect{3.6.20}
\begin{proof}
  First let us find the expected value for the given pdf:
  \begin{align*}
    &E(Y)=\mu=\int_0^\infty e^{-y}dy=\\
    &\lim_{b\rightarrow \infty}\int_0^b e^{-y}dy=\lim_{b\rightarrow \infty}[\frac{e^{-b}}{-1}+1]=1
  \end{align*}
  using the shortcut formula for variance:
  \[
    V(X)=E(X^2)-[E(X)]^2
  \]
  we find:
  \[
    V(Y)=\lim_{ b\rightarrow \infty}\int_0^b y^2e^{-y}dy -1
  \]
  \begin{align*}
    &y^2(-e^{-y})-\lim_{ b\rightarrow \infty}\int_0^b -2e^{-y}dy -1\\
    &\lim_{ b\rightarrow \infty}y^2(-e^{-y})\Big|_0^b+2\lim_{ b\rightarrow \infty}\int_0^b e^{-y}dy -1\\
    &=2\lim_{ b\rightarrow \infty}\int_0^b e^{-y}dy -1\\
    &\text{Using the result from expected value}\\
    &2(1)-1=1\\
    &V(X)=\sigma^2=1
  \end{align*}
  From page 150:
  \[
    \text{Skew=}\mu_3^{'}=\frac{E[(W-\mu)^3]}{\sigma^3}=\frac{\sum_{j=0}^3 {3 \choose j}E(W^j)(-\mu)^{3-j}}{\sigma^3}=-1+3-6+1(E(W^3))
  \]
  \begin{align*}
    &E(Y^3)=\lim_{ b\rightarrow \infty}\int_0^b y^3e^{-y}dy=\\
    &-y^3e^3\Big|_0^\infty -\lim_{ b\rightarrow \infty}\int_0^b -3y^2e^{-y}dy=\\
    &-y^3e^3\Big|_0^\infty +3[\lim_{ b\rightarrow \infty}\int_0^b y^2e^{-y}dy]\\
    &=0+3(2)=6 \therefore:
  \end{align*}
  \[
    \text{Skew}=-1+3-6+6=2
  \]
\end{proof}\\
\end{document}
